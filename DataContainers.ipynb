{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = np.pi/180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UtilityMath import (find_nearest_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Containers\n",
    "For this project, we will have a variety of results: theoretical, simulation, \n",
    "experimental.  These results can take the form of complex valued S-Parameters\n",
    "or power measurements.  They can be spectroscopic\n",
    "traces or they can be monochromatic.  It's a lot of possible combinations.\n",
    "\n",
    "The goal of the functions contained herein is to create a common interface for\n",
    "all of these different types of results so that they can be compared and plotted\n",
    "together.  For instance, we might have S-Params for a simulation and want to deduce\n",
    "what would it would look like if they were interferred as a power measurement so\n",
    "it can be compared to this physical measurement.\n",
    "\n",
    "As an additional complication, some of these results might have multiplicative offsets \n",
    "(either complex valued or power magnitude; either spectroscopic or scalar).  These are\n",
    "considered \"understandable\" and can be removed by applying scale-factors (sf) \n",
    "to the results.  These data containers will also allow us to apply these scale-factors\n",
    "to the results within the data containers and then reset them as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclature\n",
    "Within this code, I'm going to use the following conventions:\n",
    "* S; Complex-Valued Scattering Parameter\n",
    "* T = abs(S)^2; the power transmitted in an S-Parameter\n",
    "Within this convention, `'S41'` can be used to address S41 and `'T41'` would be used to address $abs(S_{41})^2$.\n",
    "\n",
    "Additionally, many of our measurements are actually interferometric.  For instance, we can imagine combining\n",
    "the outputs at ports 4 and 6 when port 1 is illuminated.  Assuming ideal combiners and symmetric waveguides, this\n",
    "would be $c\\ (S_{41} + S_{61})$ where $c$ is some complex scale factor that captures the unknown waveguide lengths.\n",
    "We will refer to this as `'S31_S61'`.  In the case of a power measurement, it would $c\\ |S_{41} + S_{61}|^2$ and\n",
    "be represented by `'T31_T61'`.  In some case, we're comparing to a specially designed \"reference waveguide\" which \n",
    "would be `'P31_R'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Theoretical Target Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmlQesqTR3yj",
    "partialCollapse": true
   },
   "outputs": [],
   "source": [
    "# Old?\n",
    "# class TargSParams:\n",
    "\n",
    "#     def __init__(self, kernel, wls):\n",
    "#         self.kernel = kernel\n",
    "#         self.wls = np.array(wls)\n",
    "#         self.rn, self.rc = kernel.shape\n",
    "\n",
    "#     def __getitem__(self, rc):\n",
    "#         if len(rc) == 2:\n",
    "#             r, c = rc\n",
    "#             val = self.kernel[r-1-self.rn, c-1]\n",
    "#             return np.full(len(self.wls), val)\n",
    "#         elif rc == 'wls':\n",
    "#             return self.wls\n",
    "#         else:\n",
    "#             print(\"I don't know what you want\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vM_Iq2KY4zTa"
   },
   "outputs": [],
   "source": [
    "K1Target = np.array(\n",
    "    [[0.400*np.exp(1j*(   0)*deg), 0.311*np.exp(1j*(  40)*deg), 0.222*np.exp(1j*(  80)*deg)],\n",
    "     [0.400*np.exp(1j*( 120)*deg), 0.311*np.exp(1j*( 160)*deg), 0.222*np.exp(1j*(-160)*deg)],\n",
    "     [0.400*np.exp(1j*(-120)*deg), 0.311*np.exp(1j*( -80)*deg), 0.222*np.exp(1j*( -40)*deg)]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhPqRIv12nxL"
   },
   "outputs": [],
   "source": [
    "K2Target = np.array(\n",
    "    [[0.467*np.exp(1j*(  26.34)*deg), 0.585*np.exp(1j*( 140.39)*deg), 0.402*np.exp(1j*( -19.92)*deg)],\n",
    "     [0.614*np.exp(1j*(  34.34)*deg), 0.425*np.exp(1j*( -66.30)*deg), 0.407*np.exp(1j*( -131.93)*deg)],\n",
    "     [0.358*np.exp(1j*(  14.63)*deg), 0.446*np.exp(1j*(  17.06)*deg), 0.629*np.exp(1j*(  74.63)*deg)]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vjwKfWTCua6"
   },
   "outputs": [],
   "source": [
    "K3Target = np.array(\n",
    "    [[0.5494*np.exp(1j*(  26.34)*deg), 0.6882*np.exp(1j*( 140.39)*deg), 0.4729*np.exp(1j*( -19.92)*deg)],\n",
    "     [0.7224*np.exp(1j*(  34.34)*deg), 0.5000*np.exp(1j*( -66.30)*deg), 0.4788*np.exp(1j*( -131.93)*deg)],\n",
    "     [0.4212*np.exp(1j*(  14.63)*deg), 0.5247*np.exp(1j*(  17.06)*deg), 0.7400*np.exp(1j*(  74.63)*deg)]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz5TDeQlGc_Q"
   },
   "outputs": [],
   "source": [
    "K4Target = np.array(\n",
    "    [[0.606*np.exp(1j*(  44.99)*deg), 0.483*np.exp(1j*( 165.15)*deg)],\n",
    "     [0.483*np.exp(1j*(  26.71)*deg), 0.606*np.exp(1j*( -33.13)*deg)]\n",
    "    ]).conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targDict = {'K1':K1Target, 'K2':K2Target, 'K3':K3Target.conj(), 'K4':K4Target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYCXQhFWJxVc"
   },
   "outputs": [],
   "source": [
    "class TargSParams:\n",
    "    def __init__(self, kernel='K1', SRef=(1.+0.j), WL=1.525):\n",
    "        transArray = targDict[kernel]\n",
    "        zArray = np.zeros_like(transArray)\n",
    "        self.SDataRaw = np.block([[zArray, transArray.T],\n",
    "                          [transArray, zArray]])\n",
    "        self.SData = self.SDataRaw.copy()\n",
    "        self.nR, self.nC = self.SData.shape\n",
    "        self.wl = WL\n",
    "        self.SRef = SRef\n",
    "\n",
    "    def getSVal(self, r, c):\n",
    "        return self.SData[r-1, c-1]\n",
    "\n",
    "    def getTVal(self, r, c):\n",
    "        return np.abs(self.SData[r-1, c-1])**2\n",
    "\n",
    "    def getSTransPart(self):\n",
    "        return self.SData[(self.nR//2):, :(self.nC//2) ]\n",
    "\n",
    "    def getTTransPart(self):\n",
    "        return np.abs(self.getSTransPart())**2\n",
    "    \n",
    "    def applyCorrectionFactor(self, CF):\n",
    "        self.SData = CF * self.SDataRaw\n",
    "\n",
    "    def resetCorrectionFactor(self):\n",
    "        self.SData = self.SDataRaw\n",
    "    \n",
    "    def getSRef(self):\n",
    "        return self.SRef\n",
    "        \n",
    "    def getMeasurement(self, key, verbose=False):\n",
    "        \"\"\"\n",
    "        key is expected to be of the form:\n",
    "        S61, P61, P61_R, P41_P61.\n",
    "        \"\"\"\n",
    "        measType = key[0] # Let's determine the measurement type from the first lettter.  'S', 'T' or 'P'\n",
    "        terms = key.split('_') # Could be interferometric.  'P41_P61' -> ['P41', 'P61']\n",
    "        nTerms = len(terms)\n",
    "        if verbose: print(terms)\n",
    "        term0 = terms[0]   # There will always be a first term.\n",
    "        if len(terms) == 2:  # If there is a second term, grap it.  Otherwise let's make one for symmetry.\n",
    "            term1 = terms[1]\n",
    "        else: \n",
    "            term1 = 'zero'\n",
    "        dataS0 = self.getSVal(eval(term0[1]), eval(term0[2])) # Grab the SParams for the first term.\n",
    "        if term1 == 'zero': # Could be zero, indicating not intererometric.  Add zeros.\n",
    "            dataS1 = 0.\n",
    "        elif term1 == 'R':  # Could be 'R', the reference waveguide.  Get it.\n",
    "            dataS1 = self.getSValR()\n",
    "        else:               # Just normal data.  Grab the SParams.\n",
    "            dataS1 = self.getSVal(eval(term1[1]), eval(term1[2]))\n",
    "        dataS = (dataS0 + dataS1)/nTerms  # Interfer the two terms.\n",
    "        if measType == 'S':\n",
    "            return (self.wl, dataS)\n",
    "        elif measType == 'T':\n",
    "            return (self.wl, np.abs(dataS)**2)\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized measurement type.  Should be 'S' or 'T'.\")\n",
    "    \n",
    "    def getMeasurementAt(self, key, wl, verbose=False):\n",
    "        \"\"\"\n",
    "        key is expected to be of the form:\n",
    "        S61, P61, P61_R, P41_P61.\n",
    "        \"\"\"\n",
    "        if(wl == self.wl):\n",
    "            wl, v = self.getMeasurement(key)\n",
    "            return v\n",
    "        else:\n",
    "            print(\"Wavelength doesn't match\")\n",
    "            return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ1 = TargSParams('K1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ1.getSVal(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ1.getMeasurement('S41')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl, sTest = targ1.getMeasurement('S41_S61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl, tTest = targ1.getMeasurement('T41_T61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(sTest)**2 == tTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKNXKIoH6zwz"
   },
   "outputs": [],
   "source": [
    "def loadSimResults(fName):\n",
    "    f = open(fName, 'r')\n",
    "    # Data consist of three lines\n",
    "    l1 = f.readline()\n",
    "    l2 = f.readline()\n",
    "    l3 = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    # First line gives the dimensions of the rest of the data\n",
    "    nR, nC, nWLs = np.fromstring(l1, dtype=np.uint32, sep='\\t')\n",
    "\n",
    "    # second line gives the wavelengths, which we convert to microns\n",
    "    wls = (10**6)*np.fromstring(l2, dtype=np.float, sep='\\t')\n",
    "    assert len(wls) == nWLs, 'wavelength data has unexpected length'\n",
    "\n",
    "    # third line gives the rest of the data.\n",
    "    textLine = l3\n",
    "    # Python iterprets 'j' as the imaginary unit\n",
    "    textLine = textLine.replace('i', 'j')\n",
    "    # Values are tab separated.  Convert to list of strings.\n",
    "    textList = textLine.split(sep='\\t')\n",
    "    # Convert to complex values.\n",
    "    numberList = [complex(w) for w in textList]\n",
    "    # Convert to numpy array\n",
    "    npArray = np.array(numberList)\n",
    "    # Check length makes sense.\n",
    "    assert len(npArray) == nC*nR*nWLs, 'data not read to expected length'\n",
    "    # Reshape array\n",
    "    npArray = npArray.reshape(nWLs, nR, nC)\n",
    "    # There is a quirk of SParams where sometimes in a 2x2, they use the transpose.  Let's undo that here.\n",
    "    if nR == 2:\n",
    "        sParams = npArray\n",
    "    else:\n",
    "        sParams = np.transpose(npArray, (0, 2, 1))\n",
    "    print(fName, ':', sParams.shape)\n",
    "    return wls, sParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls, SParams = loadSimResults(\"Simulations/K4_SIM4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SParams[0, 3, 0] #S41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls, SParams = loadSimResults(\"Simulations/Cal4_SIM4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SParams[0, 1, 0] #S21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKIrr07sLHT-"
   },
   "outputs": [],
   "source": [
    "class SimSParams:\n",
    "    def __init__(self, fName, refFName=None):\n",
    "        self.wls, self.SDataRaw = loadSimResults(fName)\n",
    "        if refFName:\n",
    "            self.wlsRef, self.SDataRef = loadSimResults(refFName)\n",
    "        else:\n",
    "            self.wlsRef, self.SDataRef = None, None\n",
    "        self.SData = self.SDataRaw.copy()\n",
    "        self.nWLs, self.nR, self.nC = self.SData.shape\n",
    "\n",
    "    def getSTrace(self, r, c):\n",
    "        return self.SData[:, r-1, c-1]\n",
    "   \n",
    "    def getTTrace(self, r, c):\n",
    "        return np.abs(self.SData[:, r-1, c-1])**2\n",
    "\n",
    "    def getSVal(self, r, c, wl):\n",
    "        iWL = find_nearest_index(self.wls, wl)\n",
    "        return self.SData[iWL, r-1, c-1]\n",
    "\n",
    "    def getTVal(self, r, c, wl):\n",
    "        iWL = find_nearest_index(self.wls, wl)\n",
    "        return np.abs(self.SData[iWL, r-1, c-1])**2\n",
    "\n",
    "    def getSTransPartSpec(self):\n",
    "        return self.SData[:, (self.nR//2):, :(self.nC//2) ]\n",
    "\n",
    "    def getSTransPart(self, wl):\n",
    "        iWL = find_nearest_index(self.wls, wl)\n",
    "        return self.SData[iWL, (self.nR//2):, :(self.nC//2) ]\n",
    "\n",
    "    def getTTransPartSpec(self):\n",
    "        return np.abs(self.SData[:, (self.nR//2):, :(self.nC//2) ])**2\n",
    "\n",
    "    def getTTransPart(self, wl):\n",
    "        iWL = find_nearest_index(self.wls, wl)\n",
    "        return np.abs(self.SData[iWL, (self.nR//2):, :(self.nC//2) ])**2\n",
    "\n",
    "    def applyCorrectionFactor(self, CF):\n",
    "        zArray = np.zeros_like(CF)\n",
    "        CFBig = np.block([[[zArray, CF.T],\n",
    "                           [CF, zArray]]])\n",
    "        self.SData =  CFBig * self.SDataRaw\n",
    "\n",
    "    def resetCorrectionFactor(self):\n",
    "        self.SData = self.SDataRaw\n",
    "        \n",
    "    def getSValR(self):\n",
    "        return self.SDataRef[:, 2-1, 1-1] #S21 or Ref\n",
    "      \n",
    "    def getMeasurement(self, key, verbose=False):\n",
    "        \"\"\"\n",
    "        key is expected to be of the form:\n",
    "        S61, P61, P61_R, P41_P61.\n",
    "        \"\"\"\n",
    "        measType = key[0] # Let's determine the measurement type from the first lettter.  'S', 'T' or 'P'\n",
    "        terms = key.split('_') # Could be interferometric.  'P41_P61' -> ['P41', 'P61']\n",
    "        nTerms = len(terms)\n",
    "        if verbose: print(terms)\n",
    "        term0 = terms[0]   # There will always be a first term.\n",
    "        if len(terms) == 2:  # If there is a second term, grap it.  Otherwise let's make one for symmetry.\n",
    "            term1 = terms[1]\n",
    "        else: \n",
    "            term1 = 'zero'\n",
    "        dataS0 = self.getSTrace(eval(term0[1]), eval(term0[2])) # Grab the SParams for the first term.\n",
    "        if term1 == 'zero': # Could be zero, indicating not intererometric.  Add zeros.\n",
    "            dataS1 = 0.\n",
    "        elif term1 == 'R':  # Could be 'R', the reference waveguide.  Get it.\n",
    "            dataS1 = self.getSValR()\n",
    "        else:               # Just normal data.  Grab the SParams.\n",
    "            dataS1 = self.getSTrace(eval(term1[1]), eval(term1[2]))\n",
    "        dataS = (dataS0 + dataS1)/nTerms  # Interfer the terms.  Note that for two terms, this is equivalent of averaging.  For 1 term, it simply takes that term.\n",
    "        if measType == 'S':\n",
    "            return (self.wls, dataS)\n",
    "        elif measType == 'T':\n",
    "            return (self.wls, np.abs(dataS)**2)\n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized measurement type.  Should be 'S' or 'T'.\")\n",
    "            \n",
    "    def getMeasurementAt(self, key, wl, verbose=False):\n",
    "        wls, vals = self.getMeasurement(key)\n",
    "        F = sp.interpolate.interp1d(wls, vals, kind='quadratic')\n",
    "        v = F(wl).item()\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1Sim = SimSParams(\"Simulations/K4_SIM4.txt\", \"Simulations/Cal4_Sim4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1Sim.getMeasurement('T31_T41');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1Sim.getMeasurement('S31_R', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Spectroscopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA-Ro9Wbi8mz",
    "partialCollapse": true
   },
   "outputs": [],
   "source": [
    "# Old?\n",
    "def getExpTrace(fName):\n",
    "    f = open(fName, 'r')\n",
    "    # Trash the first line\n",
    "    f.readline()\n",
    "    # Read the rest\n",
    "    text = f.read()\n",
    "    # free the file\n",
    "    f.close()\n",
    "\n",
    "    # Data is comma and tab deliminated, remove commas\n",
    "    text1 = text.replace(',', '')\n",
    "    # Split on tabs to get a 1D list that is 2*n long\n",
    "    text2 = text1.split()\n",
    "    # Convert string data to numbers\n",
    "    numArrayDB = [float(elem) for elem in text2]\n",
    "    # Convert to a numpy array and reshape to be n x 2\n",
    "    npArray = np.array(numArrayDB).reshape((-1,2))\n",
    "    # Convert to linear scale in power transmission\n",
    "    dbData = npArray[:, 1]\n",
    "    linData = dBToLinPower(dbData)\n",
    "    wls = npArray[:,0]\n",
    "    return wls, linData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpTrace(fName):\n",
    "    wlsRaw, dataRaw = np.array(pd.read_csv(fName, header=None)).T\n",
    "    wls = wlsRaw/1000\n",
    "    data = dataRaw\n",
    "    return wls, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFNameToKey(fName):\n",
    "    \"\"\"\n",
    "    'Experiments\\\\K4\\\\K4_T31_n15dBm_44d5K.csv' -> 'T31'\n",
    "    'Experiments\\\\K4\\\\K4_T31_R_n15d5dBm_44d5K.csv' -> 'T31_R'\n",
    "    'Experiments\\\\K4\\\\K4_T31_T41_n15d5dBm_44d5K.csv' -> 'T31_T41'\n",
    "    \"\"\"\n",
    "    parts = (fName.replace('\\\\', '_').split('_'))[3:-2]\n",
    "    key = '_'.join(parts)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFNameToDetails(fPath):\n",
    "    fName = fPath.split('\\\\')[-1]                        # 'K4_T31_T41_n15d5dBm_44d5K.csv'\n",
    "    fName2 = fName.split('.')[0]                         # 'K4_T31_T41_n15d5dBm_44d5K'\n",
    "    fNameParts = fName2.split(\"_\")                       # ['K4', 'T31', 'T41', 'n15d5dBm', '44d5K']\n",
    "    kernelCode = fNameParts[0]                           # 'K4'\n",
    "    measCode = \"_\".join(fNameParts[1:-2])                # 'T31_T41'\n",
    "    tiaResCode = fNameParts[-1]                          # '44d5K'\n",
    "    incPowerCode = fNameParts[-2]                        # 'n15d5dBm'\n",
    "    r_TIA = eval(tiaResCode.replace('d', '.').replace('K', 'e3'))                           # 44500.0\n",
    "    gc_power_dB = eval(incPowerCode.replace('dBm', '').replace('d', '.').replace('n', '-'))  # -15.5\n",
    "    gc_power_mW = 10**(gc_power_dB/10)                                                       # 0.0281\n",
    "    outDict = {'kernelCode': kernelCode,\n",
    "               'measCode': measCode,\n",
    "               'gc_power_mW': gc_power_mW,\n",
    "               'R_TIA': r_TIA}\n",
    "    return outDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertFNameToDetails('Experiments\\\\K4\\\\K4_T31_T41_n15d5dBm_44d5K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpResultSpect:\n",
    "    \n",
    "    def __init__(self, name, n, scaleFactor=1):\n",
    "        self.sf = scaleFactor\n",
    "        self.GCEffCurve = 1\n",
    "        self.n = n\n",
    "        fNames = glob.glob('Experiments/**/'+name+'_*.csv', recursive=True)\n",
    "        details =[convertFNameToDetails(fName) for fName in fNames]\n",
    "        keys = [d['measCode'] for d in details]\n",
    "        self.detailsDict = {key:detail for key, detail in zip(keys, details)}\n",
    "        self.dataDict = {key:getExpTrace(fName) for key, fName in zip(keys, fNames)}\n",
    "        print(\"Imported Objects:\", keys)\n",
    "        \n",
    "    def getMeasurement(self, key):\n",
    "        wls, VTrace = self.dataDict[key]\n",
    "        GCEffCurve = self.GCEffCurve  # mW/mW\n",
    "        PDResp =  0.8/1000  # [A/mW]\n",
    "        R_TIA = self.detailsDict[key]['R_TIA']  # Ohms\n",
    "        P_GC = self.detailsDict[key]['gc_power_mW']  # mW\n",
    "        PIn = P_GC*GCEffCurve  # mW\n",
    "        POut = VTrace/(R_TIA*PDResp)  # mW\n",
    "        T = self.sf*(POut/PIn)\n",
    "        return (wls, T)\n",
    "    \n",
    "    def getMeasurementAt(self, key, wl):\n",
    "        (wls, T) = self.getMeasurement(key)\n",
    "        iWL = find_nearest_index(wls, wl)\n",
    "        return T[iWL]\n",
    "    \n",
    "    def getTTrace(self, r, c):\n",
    "        (wls, T) = getMeasurement('T'+str(r)+str(c))\n",
    "        return (wls, T)\n",
    "        \n",
    "    def getTVal(self, r, c, wl):\n",
    "        (wls, T) = getMeasurement('T'+str(r)+str(c))\n",
    "        iWL = find_nearest_index(wls, wl)\n",
    "        return T[iWL]\n",
    "    \n",
    "#     def getTTransPart(self, wl):\n",
    "#         iWL = find_nearest_index(self.wls, wl)\n",
    "#         return np.abs(self.SData[iWL, (self.nR//2):, :(self.nC//2) ])**2\n",
    "   \n",
    "    def getTTransPartSpec(self):       \n",
    "        n = self.n // 2\n",
    "        tTransKeyArray = [['T'+str(i+1+n)+str(j+1) for j in range(n)] for i in range(n)]\n",
    "        TArray = np.array([[self.dataDict[k][1] for k in row] for row in tTransKeyArray])\n",
    "        return(self.sf/self.calCurve)*TArray\n",
    "\n",
    "    def applyCorrectionFactor(self, sf):\n",
    "        \"\"\"\n",
    "        Applies a scalar or vectorial correction factor.  For instance\n",
    "        \"\"\"\n",
    "        self.sf = sf\n",
    "        \n",
    "    def resetCorrectionFactor(self):\n",
    "        self.sf = 1\n",
    "        \n",
    "    def importGCEffCurve(self, fname, wlSF=1, fillValue=1):       \n",
    "        calCurve = np.array(pd.read_csv(fname, sep=',', header=None))\n",
    "        wlsImp, TImp = calCurve.T\n",
    "        f = sp.interpolate.interp1d(wlSF*wlsImp/1000, TImp, kind='quadratic', fill_value=fillValue, bounds_error=False)\n",
    "        randomDataValue = list(self.dataDict.values())[0]\n",
    "        wlsNew, _ = randomDataValue\n",
    "        self.GCEffCurve = f(wlsNew)\n",
    "    \n",
    "    def resetGCEffCurve(self):\n",
    "        self.GCEffCurve = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "PKeyArray = [['T'+str(i+1+n)+str(j+1) for j in range(n)] for i in range(n)]\n",
    "PKeyArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K4ExpSp = ExpResultSpect('K4', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "## Experimental Monochromatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDUW9j2DMsNk"
   },
   "outputs": [],
   "source": [
    "class ExpResult:\n",
    "    def __init__(self, transDict, portCount, WL='1.525', scaleFactor=1):\n",
    "        self.wl = WL\n",
    "        self.dataDict = transDict\n",
    "        self.sf = scaleFactor\n",
    "        n = int(np.sqrt(len(transDict)))\n",
    "        self.portCount = portCount\n",
    "        n = portCount//2\n",
    "        PKeyArray = [['T'+str(i+1+n)+str(j+1) for j in range(n)] for i in range(n)]\n",
    "        transArray = np.array([[transDict[key] for key in row] for row in PKeyArray])\n",
    "        zArray = np.zeros_like(transArray)\n",
    "        self.TData = np.block([[zArray, transArray.T],\n",
    "                               [transArray, zArray]])\n",
    "        \n",
    "    def getMeasurement(self, key):\n",
    "        return (self.wl, (self.sf)*self.dataDict[key])\n",
    "\n",
    "    def getTVal(self, r, c):\n",
    "        return (self.sf)*self.dataDict['T'+str(r)+str(c)]\n",
    "\n",
    "    def getTTransPart(self):\n",
    "        n = self.portCount//2\n",
    "        return (self.sf)*(self.TData[n:, :n])\n",
    "\n",
    "    def applyCorrectionFactor(self, sf):\n",
    "        self.sf = sf\n",
    "\n",
    "    def resetCorrectionFactor(self):\n",
    "        self.sf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
